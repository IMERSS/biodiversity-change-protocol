{"/about/":{"data":{"about-imerss#About IMERSS":"About IMERSS##Institute for Multidisciplinary Ecological Research in the Salish Sea\nIMERSS is a multidisciplinary, cross–cultural, and transboundary community of practice dedicated to long-term ecological research in the Salish Sea.\nWe strive to foster open access to science, scholarship, technology and art, encouraging individuals to play active roles attending to changes in the ecosystems that surround us."},"title":"About"},"/blog/":{"data":{"":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order."},"title":"Blog"},"/blog/2018/10/06/second-blog-post/":{"data":{"":"Text can be bold, italic, or strikethrough. Links should be blue with no underlines (unless hovered over).\nThere should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs.\nThere should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs. There should be whitespace between paragraphs.\nThere should be no margin above this first sentence.\nBlockquotes should be a lighter gray with a border along the left side in the secondary color.\nThere should be no margin below this final sentence.","components#Components":"","first-header#First Header":"This is a normal paragraph following a header. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nBacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nOn big screens, paragraphs and headings should not take up the full container width, but we want tables, code blocks and similar to take the full width.\nLorem markdownum tuta hospes stabat; idem saxum facit quaterque repetito occumbere, oves novem gestit haerebat frena; qui. Respicit recurvam erat: pignora hinc reppulit nos aut, aptos, ipsa.\nMeae optatos passa est Epiros utiliter Talibus niveis, hoc lata, edidit. Dixi ad aestum.","header-2#Header 2":" This is a blockquote following a header. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nHeader 3 This is a code block following a header. Header 4 This is an unordered list following a header. This is an unordered list following a header. This is an unordered list following a header. Header 5 This is an ordered list following a header. This is an ordered list following a header. This is an ordered list following a header. Header 6 What Follows A table A header A table A header A table A header There’s a horizontal rule above and below this.\nHere is an unordered list:\nSalt-n-Pepa Bel Biv DeVoe Kid ‘N Play And an ordered list:\nMichael Jackson Michael Bolton Michael Bublé And an unordered task list:\nCreate a sample markdown document Add task lists to it Take a vacation And a “mixed” task list:\nSteal underpants ? Profit! And a nested list:\nJackson 5 Michael Tito Jackie Marlon Jermaine TMNT Leonardo Michelangelo Donatello Raphael Definition lists can be used with Markdown syntax. Definition terms are bold.\nName Godzilla Born 1952 Birthplace Japan Color Green Tables should have bold headings and alternating shaded rows.\nArtist Album Year Michael Jackson Thriller 1982 Prince Purple Rain 1984 Beastie Boys License to Ill 1986 If a table is too wide, it should scroll horizontally.\nArtist Album Year Label Awards Songs Michael Jackson Thriller 1982 Epic Records Grammy Award for Album of the Year, American Music Award for Favorite Pop/Rock Album, American Music Award for Favorite Soul/R\u0026B Album, Brit Award for Best Selling Album, Grammy Award for Best Engineered Album, Non-Classical Wanna Be Startin’ Somethin’, Baby Be Mine, The Girl Is Mine, Thriller, Beat It, Billie Jean, Human Nature, P.Y.T. (Pretty Young Thing), The Lady in My Life Prince Purple Rain 1984 Warner Brothers Records Grammy Award for Best Score Soundtrack for Visual Media, American Music Award for Favorite Pop/Rock Album, American Music Award for Favorite Soul/R\u0026B Album, Brit Award for Best Soundtrack/Cast Recording, Grammy Award for Best Rock Performance by a Duo or Group with Vocal Let’s Go Crazy, Take Me With U, The Beautiful Ones, Computer Blue, Darling Nikki, When Doves Cry, I Would Die 4 U, Baby I’m a Star, Purple Rain Beastie Boys License to Ill 1986 Mercury Records noawardsbutthistablecelliswide Rhymin \u0026 Stealin, The New Style, She’s Crafty, Posse in Effect, Slow Ride, Girls, (You Gotta) Fight for Your Right, No Sleep Till Brooklyn, Paul Revere, Hold It Now, Hit It, Brass Monkey, Slow and Low, Time to Get Ill Code snippets like var foo = \"bar\"; can be shown inline.\nAlso, this should vertically align with this and this.\nCode can also be shown in a block element.\nfoo := \"bar\"; bar := \"foo\"; Code can also use syntax highlighting.\nfunc main() { input := `var foo = \"bar\";` lexer := lexers.Get(\"javascript\") iterator, _ := lexer.Tokenise(nil, input) style := styles.Get(\"github\") formatter := html.New(html.WithLineNumbers()) var buff bytes.Buffer formatter.Format(\u0026buff, style, iterator) fmt.Println(buff.String()) } Long, single-line code blocks should not wrap. They should horizontally scroll if they are too long. This line should be long enough to demonstrate this. Inline code inside table cells should still be distinguishable.\nLanguage Code Javascript var foo = \"bar\"; Ruby foo = \"bar\"{ Small images should be shown at their actual size.\nLarge images should always scale down and fit in the content container.","memory#Memory":"Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nRAM to use Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nMore is better Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsed RAM Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nThis is the final element on the page and there should be no margin below this. ","sizing#Sizing":"Add some sections here to see how the ToC looks like. Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nParameters available Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsing pixels Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong.\nUsing rem Bacon ipsum dolor sit amet t-bone doner shank drumstick, pork belly porchetta chuck sausage brisket ham hock rump pig. Chuck kielbasa leberkas, pork bresaola ham hock filet mignon cow shoulder short ribs biltong."},"title":"Second blog post"},"/docs/":{"data":{"":" This documentation is a work in progress.\nDetecting biodiversity change is a complex challenge, involving many “wicked problems” that communities around the world must navigate to make progress toward the goals of the UN Convention on Biological Diversity.\nHere we present a protocol to address a subset of these problems, with a focus on inferring local extinction, or extirpation.\nThis protocol is fully developed and implemented in the research article published in Plants, Planet, People. Through this documentation, we provide a walk-through of this framework, centering on a tutorial dataset."},"title":"Docs"},"/docs/baseline-analysis/":{"data":{"":"","early-assessment-of-local-extinction-risk#Early assessment of local extinction risk":"Baseline analyses offer a useful preliminary approach to assessing\nbiodiversity change. By comparing historical collections data with contemporary\n“big biodiversity data”, such as those available via the Global Biodiversity\nInformation Facility or iNaturalist, we can identify species or populations that\nmay potentially be at risk of local extinction. Keeping this approach simple,\nwe can overcome some of the immediate challenges posed by the analysis of complex\nbiodiversity data sets."},"title":"Baseline analysis"},"/docs/baseline-analysis/criteria/":{"data":{"":"","criteria-to-consider#Criteria to consider":"Coordinate uncertainty Geographic coordinates represent one of the most crucial pieces of information for biodiversity change assessments.\nOften we are confronted with limited locality information, which imposes constraints on representation of historical habitat Sometimes, the information is good enough to map species occurrences to precise locations (e.g., 30x30m2 grid cell) Sometimes, the information is good enough to specify a discrete location or habitat patch Sometimes, coordinates are generalized to the geometric centre (centroid) of a given area, with a wide radius of coordinate uncertainty Sometimes, we don’t have any coordinates at all It is exceedingly difficult if not impossible to assess the status of species or populations that lack specific locality information. At the very least, we will want to ensure our targets have coordinates:\n# Filter out records lacking coordinates (Depending on the approach, one might want to be more strict and filter records below a certain threshold of coordinate Uncertainty)\nProvenance Commonly, we are only concerned with the disappearance of native plants from the landscape.\n# Filter native species # Historical evidence Biological specimens are the strongest evidence we have for biodiversity change assessments.\n# Filter voucher specimens # Taxonomically difficult or cryptic species # Filter out graminoids # Number of occurrences The number of times a species occurs in a historical record can be useful information to consider:\nA low number of occurrences could potentially signal rarity or vulnerability. The more species occurrences, the more confidence we can have that a species was well established historically. This prior knowledge can help to inform our assessment of a species’ vulnerability to local extinction.\n# Tabulate species record counts # ","open-ended-assessments-of-potential-change#Open-ended assessments of potential change":"In order to proceed beyond an initial baseline analysis to assess possible changes in a system, we can set criteria to focus our attention (and limited resources) on high risk species that are most likely to be vulnerable.\nDepending on the criteria we set, there may emerge many potential target species or populations of concern. On the first pass, however, it is notable that this decision-making process is blind to any conservation priorities we might have (e.g., species assessed as vulnerable at a provincial or national scale), which can bias biodiversity change assessments.\n“Conservation programs often prioritize species-at-risk, even while many common species may undergo the highest relative losses (Jansen et al., 2019).”"},"title":"Target selection criteria"},"/docs/baseline-analysis/data_synthesis/":{"data":{"":"","baseline-analyses-offer-a-practical-approach#Baseline analyses offer a practical approach":"A practical approach to this difficult situation is to forego any advanced modeling practices ab initio and begin instead with a simple baseline analysis of historical vs contemporary sources of biodiversity data. This approach will generally depend on normalization of species occurrence data across multiple datasets, to support the comparison of historical and contemporary species records.\nNormalization of biodiversity data is a thorny enough problem in its own right and not treated here. For this tutorial we assume that names are aligned and any ambiguity (synonymy, etc.) is resolved between the data being compared.\nBest practices are to adhere to Darwin Core standards for species occurrence data. Different communities may prefer to adhere to different taxonomic databases. Any taxonomic standard can be observed, as long as it results in consistent mapping of taxa between datasets. ### Integrate biodiversity data and summarize ","combination-of-heterogeneous-data-in-baseline-analyses#Combination of heterogeneous data in baseline analyses":"Statistical approaches to modeling biodiversity change are often paralyzed by limitations and deficiencies inherent in biodiversity data—especially when historical and contemporary data are combined from multiple sources.\nData are commonly unstructured, or heterogeneous, lacking consistent attributes or metadata Data are often biased toward positive detections (lacking absence information) Data may be collected in ways that violate the assumptions of statistical models Georeferencing is often generalized based on vague locality information Data may be sparse, with few or perhaps only singleton records to vouch for historical populations, especially at local scales "},"title":"Data synthesis"},"/docs/baseline-analysis/differences/":{"data":{"":"","identifying-potential-changes#Identifying potential changes":"Differences between historical and contemporary biodiversity data could potentially indicate change in a system:\nIn conservation assessments, historically reported species that have not been seen within XX years are often considered ‘historical populations’ whose persistence is considered questionable (XXXX) Conversely, species that suddenly appear in a biodiversity record may signal a recent dispersal, colonization or invasion event Here, we focus specifically on “species at large”, i.e., historical reports that have gone undetected in recent decades.\n# Not seen in the last 20 years Populations or species that have gone undetected for many years may be considered at risk of extirpation and targeted for assessment. However, there are other important criteria that communities may consider before undertaking such efforts."},"title":"Comparing data"},"/docs/baseline-analysis/example/":{"data":{"":"Before the beginning of the BioGaliano project in 2015, a total of 607 vascular plant species were reported for Galiano Island, represented by 1,698 records, including 446 herbarium specimens (Fig. 1). After five years of concerted search effort, amounting to \u003e18,000 observations, we documented 560 species on the project, confirming 433/607 historical species reports (71% of the historically reported diversity) and adding 127 new species to the list.\nFigure 1. Baseline analysis of Galiano Island’s vascular plant diversity"},"title":"Example"},"/docs/extirpation/":{"data":{"":"After a gridded search effort density dataframe has been assembled, inference of extirpation risk proceeds in two stages.\nIn the first stage, we infer an posterior distribution for extirpation probability for each cell in historical and potential habitat.\nIn the second stage, these per-cell estimates are pooled into regional estimates for extirpation, forming quantified proxies for the IUCN extinction criteria, complete with uncertainty estimates.\nAt both stages, prior and posterior estimates of extirpation are modelled using Bayesian inference on distributions from the beta family."},"title":"Inferring extirpation"},"/docs/extirpation/beta/":{"data":{"":"","a-convenient-choice-for-rapid-bayesian-inference#A convenient choice for rapid Bayesian inference":"The beta distribution is a convenient choice for representing Bayesian inference on a probabilistic quantity such as probability of extirpation or probability of sighting. It is a distribution on the interval \\([0, 1]\\) which allows us to quickly estimate these probabilities and also summarise our confidence of these estimates, represented by how peaked the distribution is around its maximum. make_beta \u003c- function (prob, weight) { c(prob * weight, (1 - prob) * weight) } # Beta distribution statistics from https://en.wikipedia.org/wiki/Beta_distribution beta_mean \u003c- function (bf) { bf$alpha / (bf$alpha + bf$beta) } beta_variance \u003c- function (bf) { bf$alpha * bf$beta / ((bf$alpha + bf$beta)^2 * (bf$alpha + bf$beta + 1)) } Expand for mathematical details We model the probability of a species’ extirpation in a particular area. For consistency with mathematical treatments, we present calculations with a random variable \\(θ\\) encoding the probability of presence in the range \\([0, 1]\\) and convert to \\(1-θ\\), the probability of extirpation when we summarise our results. Observations of presence or absence \\(y_t\\) are governed by a Bernoulli process with parameter \\(θ\\), where \\(p(y_t |θ)=θ\\) if \\(y_t =1\\) represents presence. Following the notation of Royle and Dorazio (2008), we updated our prior beliefs (prior distribution \\(π(θ)\\)) using a probabilistic model (likelihood function \\(f(y|θ)\\)) to derive posterior beliefs (posterior distribution \\(π(θ|y)\\)). This produces the classical form of Bayes theorem for inference written as: $$π(θ|y) ∝ π(θ)f(y|θ)$$ (Equation 1) We modeled the probability of presence by the beta distribution on \\([0, 1]\\), which is described by two shape parameters \\(α\\) and \\(β\\) and takes the form: $$f(y|α,β) ∝ y^{(α-1)} (1-y)^{(β-1)}$$ (Equation 2) This is a convenient choice because, under the Bayesian framework, we can select a conjugate prior within this family, which leads to a posterior distribution in the same family. Given our observations of target species take the form of binary variables (all representing non-detection), these can be placed within a hierarchical Bayesian modeling context where the shape parameters \\(α\\) and \\(β\\) represent hyperparameters for our modeled distributions. "},"title":"The beta distribution"},"/docs/extirpation/region/":{"data":{"":"Having arrived at individual values for the beta parameters for each cell in a region (historical or potential), we then transfer these into beta parameters for a regional distribution using moment matching:\n# Compute beta parameters given moments # Taken from https://stats.stackexchange.com/a/12239 beta_params_from_moments \u003c- function (mu, var) { alpha \u003c- ((1 - mu) / var - 1 / mu) * mu ^ 2 beta \u003c- alpha * (1 / mu - 1) return (params = list(alpha = alpha, beta = beta)) } apply_region_moments \u003c- function (stats, mu, var) { params \u003c- beta_params_from_moments(mu, var) hdi \u003c- hdiBeta(params$alpha, params$beta, p = 0.9) fields \u003c- list(Central = rp(1 - mu), Low = rp(1 - hdi[2]), High = rp(1 - hdi[1]), alpha = rv(params$alpha), beta = rv(params$beta), mu = mu, var = var) modifyList(stats, fields) } "},"title":"Pooling search effort"},"/docs/extirpation/single_cells/":{"data":{"":" The IUCN defines a taxon as ‘presumed extinct’ “when exhaustive surveys in known and/or expected habitat … have failed to record an individual.”","what-constitutes-a-complete-search#What constitutes a complete search?":"Imagine yourself in a (30×30m) area (better yet, get out into the field to think this through!) How much time do you think you need to adequately search this area?\nThere are many factors to consider here, including the size of the target organism, the complexity of its environment, search conditions, the surveyor’s efficacy, etc..\nThis is not a simple geometric problem, or challenge of covering every (m^2) of an area. Best practices for species inventory and rare species surveys recommend the “intuitive search” as the most effective approach, because species often occupy specific niches that are unevenly distributed across the landscape.\nUnless one has data to calculate detection probabilities, it is not possible to fit a fully probabilistic model to solve this problem. Hence, we must resort to a heuristic: how much effort do we need to exhaust in an area before we are satisfied that our search is complete?\nOur method incorporates a search weight parameter (W_s) that must be defined to infer extirpation probability for a given cell. We propose this parameter as a necessary heuristic, which provides a means of overcoming the impasse posed by alternative modeling approaches (e.g., MCMC), which are data hungry and cannot be satisfied in this context.\nThis parameter should ideally be assigned a priori with careful consideration for the study system or target organism.\nExpand for mathematical details Under Bayesian inference, our beta distribution parameters on an unsuccessful Bernoulli trial (representing a failure to observe) will update from \\((α,β)\\) to \\((α,β+1)\\). However, given the search is a continuous process, we have a free parameter representing the quantity of search effort that represents a discrete “trial”—our search effort \\(S_t\\) in a particular cell results in a posterior update to \\((α,β+S_t W_s)\\) where \\(W_s\\) represents the weighting applied to search effort. This weighting depends on many factors influencing the efficacy of initial intuitively reasoned search efforts, including the searcher's efficiency, the species' detectability, or the search conditions. Hence, this free parameter should be considered in relation to \\(W_p\\). Our weighting was set by eliciting a defensible level of confidence in extirpation given varying amounts of search effort within a single \\(900m^2\\) cell, leading to a value \\(W_s\\) of \\(15\\) (Supplementary Materials). "},"title":"Effective search effort"},"/docs/extirpation_historical/":{"data":{"":""},"title":"Inferring extirpation in historical habitat"},"/docs/extirpation_historical/example-i/":{"data":{"":" This map shows the accumulated search effort for Primula pauciflora over its historical habitat covering 9 grid cells in Bellhouse Park:\nprim_agm \u003c- read.csv(\"Analysis_outputs/Intermediate/Primula pauciflora_accepted_grouped_merged.csv\") prim_historical \u003c- prim_agm %\u003e% dplyr::filter(assigned_community == 77) prim_sf = assign_cell_geometry_sf(prim_historical, galgrid) pal \u003c- colorNumeric(palette = \"viridis\", domain = range(c(0, prim_sf$search_effort), na.rm = TRUE)) m \u003c- leaflet(data = prim_sf) %\u003e% # Add a Tiles layer to the map addProviderTiles(\"Esri.WorldImagery\") %\u003e% # Add the grid layer to the map addPolygons(fillColor = ~pal(search_effort), fillOpacity = 0.8, color = \"#BDBDC3\", weight = 1) %\u003e% # Add a legend addLegend(pal = pal, values = c(0, max(prim_sf$search_effort, na.rm = TRUE)), opacity = 0.8, title = \"Accumulated Search Effort in ks\") # Print the map m The table that this plot is generated from is in the AGM (accepted, grouped, merged) format, output by the data pipeline which aggregates search trace data, grids it into cells and intersects it with habitat polygons. Here is the data covering the 9 Bellhouse Park cells:\nHere is a description of the columns in this table:\nAGM Column Description cell_id Numeric cell id, allocated to a grid cell as configured in the project’s config.R file and manipulated by the utilities in geomUtil.R effortId A string which summarises each of the search efforts contributing to this search cell. This is purely for traceability and is not used by the analysis computing extirpation probability search_effort Total accumulated search effort for this grid cell measured in ksec by all observers fringe_dist The distance of this cell from historical habitat - these values are all 0 above since the cells lie within the historical habitat assigned_community The historical community to which this cell is assigned. These numbers are taken from row numbers in the historical plant records table after filtering for those with coordinates - for this analysis in target_plant_records_2024.csv area Effective area of the grid cell in square metres after intersecting it with valid habitat polygons - for this analysis, a full cell will be approximately 900 sqm area_prop The proportion that the effective grid cell area is of a standard full grid cell - for this analysis, 900 sqm These cell data are passed for computing regional statistics as the second argument to the analyse_accepted function in Analyse.R:\nanalyse_accepted(thisTarget, accepted_grouped_merged, habitat_to_centres, exp_weight = exp_weight, solow_prob = solow_low) Here exp_weight is the exponential kernel distance weighting parameter and solow_prob is the Solow prior probability of sighting. This produces posterior regional statistics for extirpation in historical habitat as follows:\ntarget_stats \u003c- read.csv(\"Analysis_outputs/Intermediate/Primula pauciflora_stats.csv\") target_stats_historical \u003c- target_stats %\u003e% dplyr::filter(Population == 77) paged_table(target_stats_historical) These show the computed parameters of the posterior beta distribution for extirpation expressed in two different forms - the standard (alpha, beta) representation and (mu, var) as parameters for the central estimate for sighting probability and its dispersion. Confidence bands are placed for this at [91.2%, 100.0%].\nHere is this posterior distribution graphed out:"},"title":"Example I"},"/docs/extirpation_historical/example-ii/":{"data":{"":" This map shows the accumulated search effort for Crassula connata over its historical habitat covering 10 grid cells in Bellhouse Park:\ncracon_agm \u003c- read.csv(\"Analysis_outputs/Intermediate/Crassula connata_accepted_grouped_merged.csv\") cracon_historical \u003c- cracon_agm %\u003e% dplyr::filter(assigned_community == 44) cracon_sf = assign_cell_geometry_sf(cracon_historical, galgrid) pal \u003c- colorNumeric(palette = \"viridis\", domain = range(c(0, cracon_sf$search_effort), na.rm = TRUE)) m \u003c- leaflet(data = cracon_sf) %\u003e% # Add a Tiles layer to the map addProviderTiles(\"Esri.WorldImagery\") %\u003e% # Add the grid layer to the map addPolygons(fillColor = ~pal(search_effort), fillOpacity = 0.8, color = \"#BDBDC3\", weight = 1) %\u003e% # Add a legend addLegend(pal = pal, values = c(0, max(cracon_sf$search_effort, na.rm = TRUE)), opacity = 0.8, title = \"Accumulated Search Effort in ks\") # Print the map m The table that this plot is generated from is in the AGM (accepted, grouped, merged) format, output by the data pipeline which aggregates search trace data, grids it into cells and intersects it with habitat polygons. Here is the data covering the 6 Bellhouse Park cells:\nThis data format is explained in the previous example\nThis produces posterior regional statistics for extirpation in historical habitat as follows:\ntarget_stats \u003c- read.csv(\"Analysis_outputs/Intermediate/Crassula connata_stats.csv\") target_stats_historical \u003c- target_stats %\u003e% dplyr::filter(Population == 44) paged_table(target_stats_historical) These show the computed parameters of the posterior beta distribution for extirpation expressed in two different forms - the standard (alpha, beta) representation and (mu, var) as parameters for the central estimate for sighting probability and its dispersion. Confidence bands are placed for this at [90.7%, 100.0%].\nHere is this posterior distribution graphed out:"},"title":"Example II"},"/docs/extirpation_historical/meconella/":{"data":{"":" This map shows the accumulated search effort for Meconella oregana over historical community 55\ntarget_agm \u003c- read.csv(\"Analysis_outputs/Intermediate/Meconella oregana_accepted_grouped_merged.csv\") target_historical \u003c- target_agm %\u003e% dplyr::filter(assigned_community == 55) target_sf = assign_cell_geometry_sf(target_historical, galgrid) pal \u003c- colorNumeric(palette = \"viridis\", domain = range(c(0, target_sf$search_effort), na.rm = TRUE)) m \u003c- leaflet(data = target_sf) %\u003e% # Add a Tiles layer to the map addProviderTiles(\"Esri.WorldImagery\") %\u003e% # Add the grid layer to the map addPolygons(fillColor = ~pal(search_effort), fillOpacity = 0.8, color = \"#BDBDC3\", weight = 1) %\u003e% # Add a legend addLegend(pal = pal, values = c(0, max(target_sf$search_effort, na.rm = TRUE)), opacity = 0.8, title = \"Accumulated Search Effort in ks\") # Print the map m "},"title":"Meconella oregana"},"/docs/extirpation_historical/plagiobothrys/":{"data":{"":" This map shows the accumulated search effort for Plagiobothrys tenellus over historical community 66\ntarget_agm \u003c- read.csv(\"Analysis_outputs/Intermediate/Plagiobothrys tenellus_accepted_grouped_merged.csv\") target_historical \u003c- target_agm %\u003e% dplyr::filter(assigned_community == 66) target_sf = assign_cell_geometry_sf(target_historical, galgrid) pal \u003c- colorNumeric(palette = \"viridis\", domain = range(c(0, target_sf$search_effort), na.rm = TRUE)) m \u003c- leaflet(data = target_sf) %\u003e% # Add a Tiles layer to the map addProviderTiles(\"Esri.WorldImagery\") %\u003e% # Add the grid layer to the map addPolygons(fillColor = ~pal(search_effort), fillOpacity = 0.8, color = \"#BDBDC3\", weight = 1) %\u003e% # Add a legend addLegend(pal = pal, values = c(0, max(target_sf$search_effort, na.rm = TRUE)), opacity = 0.8, title = \"Accumulated Search Effort in ks\") # Print the map m This map shows the accumulated search effort for Plagiobothrys tenellus over historical community 67\ntarget_historical \u003c- target_agm %\u003e% dplyr::filter(assigned_community == 67) target_sf = assign_cell_geometry_sf(target_historical, galgrid) pal \u003c- colorNumeric(palette = \"viridis\", domain = range(c(0, target_sf$search_effort), na.rm = TRUE)) m \u003c- leaflet(data = target_sf) %\u003e% # Add a Tiles layer to the map addProviderTiles(\"Esri.WorldImagery\") %\u003e% # Add the grid layer to the map addPolygons(fillColor = ~pal(search_effort), fillOpacity = 0.8, color = \"#BDBDC3\", weight = 1) %\u003e% # Add a legend addLegend(pal = pal, values = c(0, max(target_sf$search_effort, na.rm = TRUE)), opacity = 0.8, title = \"Accumulated Search Effort in ks\") # Print the map m "},"title":"Plagiobothrys tenellus"},"/docs/extirpation_potential/":{"data":{"":"Inference of extirpation in potential habitat proceeds as with inference for historical habitat, with the additional element to the analysis that our prior probability of extirpation is modified by a distance kernel, which assigns decreasing probability of persistence with increasing distance from historical habitat."},"title":"Inferring extirpation in potential habitat"},"/docs/extirpation_potential/distance_prior/":{"data":{"":"Estimating the likelihood of a plant’s occurrence beyond the extent of its historical habitat presents a Wallacean dilemma, as species often exhibit restricted distributions despite the apparent availability of suitable habitat (Lomolino, Riddle and Brown., 2006). To address this dilemma, we applied the negative exponential distance weighting system widely used in metapopulation ecology to model patch-occupancy dynamics (Hanski, 1994; Hanski et al., 2017; Yeiser et al., 2021; Hanski \u0026 Ovaskainen, 2002). This method was chosen for its analytical simplicity, based on the assumption that patch occupancy probabilities decrease with varying distance from historical source populations, depending on the rarity patterns of target plants.\nWe selected kernel values by linking them with rarity types (Kruckeberg and Rabinowitz, 1985; Crisfield et al., 2024) and then assigning typologies to target species. Kernel assignments were justified by comparing plotted distance decay rates with regional distribution patterns of target plants. Validation was also drawn from comparisons with the observed distance decay rates of detected targets relative to the position of first historical records (Supplementary Materials). This gives rise to a distance-based prior distribution for presence (P_d = exp(-\\gamma d) ) where d represents the distance of the patch from a historical record and (\\gamma) represents the kernel value."},"title":"Inverse distance prior"},"/docs/extirpation_potential/example-i/":{"data":{"":" This map shows the accumulated search effort for Primula pauciflora over both historical and potential habitat:\nprim_agm \u003c- read.csv(\"Analysis_outputs/Intermediate/Primula pauciflora_accepted_grouped_merged.csv\") prim_sf = assign_cell_geometry_sf(prim_agm, galgrid) pal \u003c- colorNumeric(palette = \"viridis\", domain = range(c(0, prim_sf$search_effort), na.rm = TRUE)) m \u003c- leaflet(data = prim_sf) %\u003e% addProviderTiles(\"Esri.WorldImagery\") %\u003e% # Add the grid layer to the map addPolygons(fillColor = ~pal(search_effort), fillOpacity = 0.8, color = \"#BDBDC3\", weight = 1) %\u003e% # Add a legend addLegend(pal = pal, values = c(0, max(prim_sf$search_effort, na.rm = TRUE)), opacity = 0.8, title = \"Accumulated Search Effort in ks\") # Print the map m See the treatment of historical habitat for explanation of the data format underlying this plot.\nThis produces posterior regional statistics for extirpation across all habitat as follows:\nThese show the computed parameters of the posterior beta distribution for extirpation expressed in two different forms - the standard (alpha, beta) representation and (mu, var) as parameters for the central estimate for sighting probability and its dispersion. Confidence bands are placed for this at [68.3%, 100.0%].\nHere is this posterior distribution graphed out - whilst the most probable extirpation value is 100% because of the folded nature of the beta distribution, this is a more dispersed distribution than that for historical habitat and the central estimate of extirpation probability is 86.3%."},"title":"Example I"},"/docs/extirpation_potential/example-ii/":{"data":{"":" This map shows the accumulated search effort for Crassula connata over both historical and potential habitat:\ncracon_agm \u003c- read.csv(\"Analysis_outputs/Intermediate/Crassula connata_accepted_grouped_merged.csv\") cracon_sf = assign_cell_geometry_sf(cracon_agm, galgrid) pal \u003c- colorNumeric(palette = \"viridis\", domain = range(c(0, cracon_sf$search_effort), na.rm = TRUE)) m \u003c- leaflet(data = cracon_sf) %\u003e% addProviderTiles(\"Esri.WorldImagery\") %\u003e% # Add the grid layer to the map addPolygons(fillColor = ~pal(search_effort), fillOpacity = 0.8, color = \"#BDBDC3\", weight = 1) %\u003e% # Add a legend addLegend(pal = pal, values = c(0, max(cracon_sf$search_effort, na.rm = TRUE)), opacity = 0.8, title = \"Accumulated Search Effort in ks\") # Print the map m See the treatment of historical habitat for explanation of the data format underlying this plot.\nThis produces posterior regional statistics for extirpation across all habitat as follows:\nThese show the computed parameters of the posterior beta distribution for extirpation expressed in two different forms - the standard (alpha, beta) representation and (mu, var) as parameters for the central estimate for sighting probability and its dispersion. Confidence bands are placed for this at [76.7%, 100.0%].\nHere is this posterior distribution graphed out - whilst the most probable extirpation value is 100% because of the folded nature of the beta distribution, this is a more dispersed distribution than that for historical habitat and the central estimate of extirpation probability is 90.8%."},"title":"Example II"},"/docs/extirpation_potential/kernel_validation/":{"data":{"":"For detected species, negative-exponential kernels were estimated empirically by regressing the distances of species detections from the position of initial records, against the background of unsuccessful detections. This was done with the brms package (Bürkner, 2017) using Markov Chain Monte Carlo sampling in STAN. Our regression applies the Bernoulli distribution family to the target detection via a modelling function (occupancy_i 〜 q .exp( d_i) ) where is the kernel width, q scales the overall detection rate (not of interest to this analysis) and di is the distance from historical habitat of occupancy observation (occupancy_i).\n## Calibrating "},"title":"Kernel validation"},"/docs/extirpation_potential/rarity_types/":{"data":{"":"","xxxx#XXXX":" ## Calibrating "},"title":"Rarity types"},"/docs/inferring_extirpation_risk/":{"data":{"":"","detection-frequency#Detection frequency":"Another metric that might be considered in evaluating extirpation risk is detection frequency or sighting rate. Whether a species was observed only once historically, or multiple times, before going unreported, might influence our prior belief in the likelihood of its persistence or extirpation.\nIf there are many records vouching for a species’ historical occurrence, we might have greater confidence that it was a well established population\nIf a species is only reported once or twice, historical populations may have been small or non-viable, or perhaps the species is simply rare and overlooked\nSighting rates constitute useful prior knowledge and can be used to calculate extinction probabilities."},"title":"Inferring extirpation risk"},"/docs/inferring_extirpation_risk/example/":{"data":{"":" Let’s consider two vascular plant species as a case study for inferring extinction probabilities."},"title":"Example"},"/docs/inferring_extirpation_risk/solow_calculation/":{"data":{"":"","inferring-local-extinction-based-on-limited-occurrence-data#Inferring local extinction based on limited occurrence data":"XXXXXXX\nExpand for mathematical details Solow (1993) provides a framework for determining a reasonable prior distribution for belief about species extinction when observational data are limited. Their Equation 3 presents a Bayes Factor for summarizing evidence in favor of extinction, given by: \\(B(t) = (n -1) / [(T/t_n )^(n - 1) - 1]\\) where \\(n\\) is the number of observations and \\(Ti\\) represents the \\(ith\\) sighting time and \\(T\\) is the present date. "},"title":"Solow calculation (Prior I)"},"/docs/mapping_habitat/":{"data":{"":"","mapping-habitat#Mapping habitat":"Habitat can be represented in many ways, ranging from complex species distribution models to relatively simple ecosystem mapping or site classification data.\nIn this tutorial, we use high resolution (1:5,000 scale) site classification mapping to map habitat for our target species. This spatial data takes the shape of polygons circumscribing different ecosystem types or areas of land use. This versatile approach should be accessible to many communities, wherever land classification or terrestrial ecosystem mapping data are available. Otherwise, habitat can be mapped based on orthoimagery generated using a variety of methods (e.g., satellite, drone).\nFiltering site classification mapping based on habitat types for target species XXXXXXX\nConverting polygons to gridded representation of habitat XXXXX\nFor this methodology, a key consideration is to ensure that the grid scale corresponds with the precision in features representing search effort.\n## Convert polygons to grid Calculate proportional representation of habitat within grid cells ## Calculate prop. of habitat falling within grid cells "},"title":"Representing habitat"},"/docs/mapping_habitat/example/":{"data":{"":" This is a placeholder page that shows you how to use this template site.\nDo you have any example applications or code for your users in your repo or elsewhere? Link to your examples here."},"title":"Example"},"/docs/mapping_habitat/historical_habitat/":{"data":{"":"","defining-area-of-habitat-patches-based-on-coordinate-uncertainty-of-target--occurrence-records#Defining area of habitat patches based on coordinate uncertainty of target  occurrence records":"XXXXXXX","mapping-target-species#Mapping target species":"XXXXXXX"},"title":"Defining historical habitat patches"},"/docs/mapping_habitat/potential_habitat/":{"data":{"":"","expanding-the-habitat-grid-to-include-potential-habitat#Expanding the habitat grid to include potential habitat":"XXXXX","mapping-potential-habitat#Mapping potential habitat":"In the previous habitat mapping vignette, we defined the extent of historical habitat."},"title":"Defining potential habitat patches"},"/docs/overview/":{"data":{"":"Extinction events are the sum of all extirpation events, with the vanishing of all individuals of a species. Thus, to address the global threat of biodiversity loss, communities must develop systems for the early detection and prevention of extinction as it occurs locally.\nWe need systems that allow communities to track biodiversity change locally, to curb biodiversity loss at its source."},"title":"Overview"},"/docs/overview/extinction_criteria/":{"data":{"":"To meet global standards set for inferring extinction, the practical application of statistical inference must be framed around criteria set out by the International Union for the Conservation of Nature (IUCN, 2012) for the assessment of extinction events.\nThe IUCN defines a taxon as ‘presumed extinct’ (in our case, equivalent to extirpated—or locally extinct) “when exhaustive surveys in known and/or expected habitat, at appropriate times (diurnal, seasonal, annual), throughout its historic range have failed to record an individual.”\nHowever, it remains a major challenge to determine the evidentiary thresholds implied by these criteria (‘exhaustive’, ‘expected’, ‘appropriate’), not only to clarify the formal requirements for claims regarding extirpation but also to inform effective search methods and to assess the feasibility of meeting these requirements.\nOur goal is to transform the abstract problem of assessing extinction into a structured, measurable, and actionable process. To that end, this documentation clarifies the steps and assumptions underlying the IUCN extinction criteria and proposes a practical methodology for applying them to infer extinction events in real-world contexts."},"title":"IUCN extinction criteria"},"/docs/references/":{"data":{"":" This is a placeholder page that shows you how to use this template site.\nIf your project has an API, configuration, or other reference - anything that users need to look up that’s at an even lower level than a single task - put (or link to it) here. You can serve and link to generated reference docs created using Doxygen, Javadoc, or other doc generation tools by putting them in your static/ directory. Find out more in Adding static content. For OpenAPI reference, Docsy also provides a Swagger UI layout and shortcode that renders Swagger UI using any OpenAPI YAML or JSON file as source."},"title":"References"},"/docs/search_effort/":{"data":{"":"Search effort is represented as a per-observer search time per gridded cell represented in ksec. Search effort is applied only to valid potential or historical habitat for the target taxon. Where the habitat model indicates that only part of a grid cell is valid habitat, the imputed search effort is scaled up proportionally.\n# From Analyse.R, # Assemble the cells which truly lie within the habitat together with their proportion of overlap analyse_target \u003c- function (thisTarget, detected = FALSE) { .... effortCells_intersect \u003c- st_intersection((accepted_grouped_sf %\u003e% filter(search_effort \u003e 0)), allHabitat) %\u003e% mutate(area = st_area(.) %\u003e% as.numeric(), area_prop = area / oneArea) %\u003e% select(cell_id, area, area_prop) %\u003e% st_drop_geometry() } "},"title":"Search effort"}}